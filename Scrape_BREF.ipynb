{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d903b781-0b4f-47dc-b127-a1ab769be6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70432da8-8eaa-4826-9fb0-3cbbed71d2d7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e840f0-ffcb-42e8-baa6-9b811e495cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoupFromURL(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def extractTable(soup, table_id):\n",
    "    tbl = soup.find('table', attrs = {'id' : table_id})\n",
    "    if tbl is None:\n",
    "        raise ValueError(f\"Could not find table with id {table_id}\")\n",
    "    return tbl\n",
    "\n",
    "def tableHeader(table_soup):\n",
    "    h = table_soup.find('thead')\n",
    "    head_row = h.find_all('tr')[-1]\n",
    "    labs = {x['data-stat'] : x['aria-label'] for x in head_row.find_all('th')}\n",
    "    return labs\n",
    "\n",
    "def tableData(table_soup, use_labels = False):\n",
    "    header = tableHeader(table_soup)\n",
    "    data = {k : [] for k in header.keys()}\n",
    "    data['id'] = []\n",
    "    body = table_soup.find('tbody')\n",
    "    rows = body.find_all('tr')\n",
    "    for row in rows:\n",
    "        if row.get('class') is not None:\n",
    "            continue\n",
    "        cells = row.find_all('th') + row.find_all('td')\n",
    "        for entry in cells:\n",
    "            d = entry['data-stat']\n",
    "            val = entry.text\n",
    "            data[d].append(val)\n",
    "            if entry.get('data-append-csv'):\n",
    "                data['id'].append(entry.get('data-append-csv'))\n",
    "    data = pd.DataFrame(data)\n",
    "    if use_labels:\n",
    "        data = data.rename(columns = header)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def scrapePage(url, table_id, use_labels = False, sleep = 3):\n",
    "    time.sleep(sleep)\n",
    "    soup = getSoupFromURL(url)\n",
    "    tbl = extractTable(soup, table_id)\n",
    "    data = tableData(tbl, use_labels)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28024b65-60d5-4141-b188-f45728816749",
   "metadata": {},
   "source": [
    "# Cleaning and Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805d8ab0-1009-4a7e-933f-a455ff750e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSalary(salary):\n",
    "    if salary == '': return None\n",
    "    salary = salary.replace('$', '').replace(',', '')\n",
    "    salary = int(salary) / 1000000\n",
    "    return salary\n",
    "\n",
    "def cleanSalaryTable(salary_table):\n",
    "    non_numerics = ['Rk', 'Player', 'Tm', 'id']\n",
    "    for col in salary_table.columns:\n",
    "        if col in non_numerics: continue\n",
    "        salary_table[col] = salary_table[col].apply(cleanSalary)\n",
    "    return salary_table\n",
    "\n",
    "def gatherSalary():\n",
    "    salary = scrapePage(\"https://www.basketball-reference.com/contracts/players.html\", 'player-contracts', use_labels = True)\n",
    "    salary = cleanSalaryTable(salary)\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d9eb6c-4813-4b88-a49d-2623d8b30d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAdvanced(adv_table):\n",
    "    non_numerics = ['name_display', 'team_name_abbr', 'pos', 'awards', 'id']\n",
    "    for col in adv_table.columns:\n",
    "        if col in non_numerics: continue\n",
    "        adv_table[col] = adv_table[col].replace('', None)\n",
    "        if adv_table[col].str.contains(\"\\.\").sum() > 0:\n",
    "            adv_table[col] = adv_table[col].astype(np.float32)\n",
    "        else:\n",
    "            adv_table[col] = adv_table[col].astype(np.int32)\n",
    "    return adv_table\n",
    "\n",
    "def gatherAdvanced(start_yr, end_yr):\n",
    "    df_list = []\n",
    "    for yr in tqdm(range(start_yr, end_yr + 1)):\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_{yr}_advanced.html\"\n",
    "        raw_df = scrapePage(url, \"advanced\")\n",
    "        clean_df = cleanAdvanced(raw_df)\n",
    "        clean_df['year'] = yr\n",
    "        df_list.append(clean_df)\n",
    "    final_df = pd.concat(df_list, axis = 0)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69a33f-810f-4057-8f83-c61cc6851542",
   "metadata": {},
   "source": [
    "# Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ad4d21-059b-4eea-902f-963c453ebf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:35<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "advanced = gatherAdvanced(2018, 2025)\n",
    "salary = gatherSalary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50fb1fe-04e1-41cb-b090-221572b58481",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced.to_csv('data/advanced.csv', index = False)\n",
    "salary.to_csv('data/salary.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
